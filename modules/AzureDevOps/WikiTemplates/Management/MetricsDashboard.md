# Metrics Dashboard

## Executive Summary

This page provides a centralized view of program health metrics, KPIs, and performance indicators. Dashboards are updated in real-time and reviewed weekly with leadership.

**Last Updated**: [Auto-updated via Azure DevOps]  
**Report Period**: [Current Sprint/Quarter]

---

## Program Health Status

### Overall Program Status: ğŸŸ¢ Green

| Area | Status | Trend | Notes |
|------|--------|-------|-------|
| **Schedule** | ğŸŸ¢ Green | â†”ï¸ Stable | On track for Q1 milestones |
| **Budget** | ğŸŸ¢ Green | â†—ï¸ Improving | 75% spent, 80% timeline elapsed |
| **Scope** | ğŸŸ¡ Yellow | â†˜ï¸ At Risk | 2 features deferred to Q2 |
| **Quality** | ğŸŸ¢ Green | â†—ï¸ Improving | Zero P1 bugs, test coverage 85% |
| **Team Health** | ğŸŸ¢ Green | â†”ï¸ Stable | Morale 7.8/10, low attrition |
| **Risks** | ğŸŸ¡ Yellow | â†˜ï¸ Watch | 5 active risks, 2 critical |

**Status Definitions**:
- ğŸŸ¢ **Green**: On track, no intervention needed
- ğŸŸ¡ **Yellow**: At risk, monitoring closely, mitigation in place
- ğŸ”´ **Red**: Off track, immediate action required, escalated

---

## Key Performance Indicators (KPIs)

### Delivery KPIs

#### Sprint Velocity
**Current**: 82 SP | **Target**: 85 SP | **Status**: ğŸŸ¢ 96% of target

```
ğŸ“Š Velocity Trend (Last 6 Sprints):
Sprint 13: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 75 SP
Sprint 14: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 78 SP
Sprint 15: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 78 SP
Sprint 16: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 85 SP (Peak)
Sprint 17: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 82 SP
Sprint 18: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 82 SP (Current)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Average: 80 SP | Std Dev: Â±3.8 SP | Predictability: High
```

**Analysis**: Velocity stable and predictable. Slight dip from Sprint 16 peak due to holiday absences. Trending toward 80-85 SP range.

---

#### Sprint Commitment Reliability
**Current**: 94% | **Target**: >90% | **Status**: âœ… Exceeding target

| Sprint | Committed | Completed | % | Status |
|--------|-----------|-----------|---|--------|
| Sprint 15 | 85 SP | 78 SP | 92% | ğŸŸ¢ |
| Sprint 16 | 90 SP | 85 SP | 94% | ğŸŸ¢ |
| Sprint 17 | 87 SP | 82 SP | 94% | ğŸŸ¢ |
| **Sprint 18** | **87 SP** | **82 SP** | **94%** | **ğŸŸ¢** |

**Analysis**: Excellent commitment reliability over last 4 sprints. Improved estimation accuracy and better understanding of team capacity.

---

#### Lead Time & Cycle Time

**Lead Time** (Idea â†’ Production): 12.5 days | **Target**: <15 days | **Status**: âœ…

**Cycle Time** (Started â†’ Done): 4.2 days | **Target**: <5 days | **Status**: âœ…

```
ğŸ“Š Cycle Time Breakdown:
Development:     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 2.5 days (60%)
Code Review:     â–ˆâ–ˆâ–ˆ 0.5 days (12%)
Testing:         â–ˆâ–ˆâ–ˆâ–ˆ 0.8 days (19%)
Deployment:      â–ˆâ–ˆ 0.4 days (9%)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total: 4.2 days
```

**Analysis**: Cycle time under target. Code review improved significantly (8h â†’ 4.2h) after implementing review buddy system.

---

### Quality KPIs

#### Defect Metrics

**Production Bugs**: 0 P1, 2 P2, 5 P3 | **Target**: <3 P1+P2 | **Status**: âœ…

**Defect Density**: 0.8 bugs/1000 LOC | **Target**: <1.0 | **Status**: âœ…

**Bug Resolution Time**:
- P1 (Critical): 18 hours avg | **Target**: <24h | **Status**: âœ…
- P2 (High): 4.5 days avg | **Target**: <3 days | **Status**: âš ï¸
- P3 (Medium): 12 days avg | **Target**: <10 days | **Status**: âš ï¸

```
ğŸ“Š Bug Trend (Last 6 Sprints):
Sprint 13: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 8 bugs
Sprint 14: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 6 bugs
Sprint 15: â–ˆâ–ˆâ–ˆâ–ˆ 4 bugs
Sprint 16: â–ˆâ–ˆâ–ˆâ–ˆ 4 bugs
Sprint 17: â–ˆâ–ˆ 2 bugs
Sprint 18: 0 bugs (Best ever! ğŸ‰)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Trend: â†˜ï¸ Decreasing (Excellent)
```

**Analysis**: Best quality sprint on record. Zero production bugs. P2/P3 resolution time needs improvement - team focused on features over bug fixes.

---

#### Test Coverage

**Overall Coverage**: 85% | **Target**: >80% | **Status**: âœ…

**Coverage by Layer**:
- Unit Tests: 92% (Target: >90%) âœ…
- Integration Tests: 78% (Target: >75%) âœ…
- E2E Tests: 65% (Target: >60%) âœ…
- API Tests: 88% (Target: >85%) âœ…

**Test Execution**:
- Total Tests: 3,247 tests
- Execution Time: 12 minutes (Target: <15 min) âœ…
- Flaky Tests: 3 (Target: <5) âœ…
- Pass Rate: 99.8% (Target: >99%) âœ…

---

#### Code Quality Metrics

**Code Review Coverage**: 100% (All PRs reviewed) âœ…

**Code Review Cycle Time**: 4.2 hours avg | **Target**: <6 hours | **Status**: âœ…

**Technical Debt Ratio**: 18% | **Target**: <20% | **Status**: ğŸŸ¡

**SonarQube Rating**: A (Target: A or B) âœ…
- Maintainability: A
- Reliability: A
- Security: A
- Code Smells: 87 (Target: <100) âœ…
- Security Hotspots: 2 (Target: <5) âœ…

---

### Performance KPIs

#### System Performance

**API Response Time (P95)**: 320ms | **Target**: <300ms | **Status**: ğŸŸ¡

```
ğŸ“Š Response Time by Endpoint (P95):
GET  /api/users:          â–ˆâ–ˆâ–ˆâ–ˆ 180ms âœ…
POST /api/auth:           â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 250ms âœ…
GET  /api/dashboard:      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 520ms âŒ (Needs optimization)
GET  /api/analytics:      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 290ms âœ…
POST /api/payments:       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 210ms âœ…
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Average: 320ms (Target: <300ms)
```

**Analysis**: Dashboard endpoint is the bottleneck. Optimization ticket created for Sprint 19.

---

**Uptime**: 99.7% | **Target**: >99.5% | **Status**: âœ…

**Incidents**:
- P1 (Critical): 0 this month
- P2 (High): 1 this month (Database timeout - resolved in 2 hours)
- P3 (Medium): 3 this month

**MTTR (Mean Time To Recovery)**: 1.8 hours | **Target**: <4 hours | **Status**: âœ…

---

#### Deployment Metrics (DORA)

**Deployment Frequency**: 8 deployments/week | **Target**: Daily (5+/week) | **Status**: âœ…

**Lead Time for Changes**: 12.5 days | **Target**: <15 days | **Status**: âœ…

**Change Failure Rate**: 8% | **Target**: <15% | **Status**: âœ…

**Mean Time to Recovery**: 1.8 hours | **Target**: <4 hours | **Status**: âœ…

**DORA Rating**: ğŸŸ¢ **Elite** (All 4 metrics in elite range)

---

### Business KPIs

#### User Growth

**Active Users**: 847 | **Target**: 1,000 by Q1 end | **Status**: ğŸŸ¡ 85% of target

```
ğŸ“Š User Growth Trend:
Week 1:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 623 users
Week 2:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 701 users (+12%)
Week 3:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 768 users (+10%)
Week 4:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 847 users (+10%)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Growth Rate: +10%/week | Target: +15%/week
```

**User Segments**:
- Free Tier: 712 (84%)
- Pro Tier: 98 (12%)
- Enterprise Tier: 37 (4%)

**Analysis**: Steady growth but below target. Need to accelerate onboarding and marketing efforts.

---

#### User Engagement

**Daily Active Users (DAU)**: 423 (50% of total) | **Target**: >40% | **Status**: âœ…

**Weekly Active Users (WAU)**: 654 (77% of total) | **Target**: >70% | **Status**: âœ…

**Monthly Active Users (MAU)**: 831 (98% of total) | **Target**: >90% | **Status**: âœ…

**Stickiness (DAU/MAU)**: 51% | **Target**: >40% | **Status**: âœ…

**Session Duration**: 18 minutes avg | **Target**: >15 minutes | **Status**: âœ…

**Session Frequency**: 4.2 sessions/week | **Target**: >3 sessions/week | **Status**: âœ…

---

#### Customer Satisfaction

**Net Promoter Score (NPS)**: 42 | **Target**: >40 | **Status**: âœ…

```
ğŸ“Š NPS Breakdown:
Promoters (9-10):  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 52% ğŸ˜„
Passives (7-8):    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 20% ğŸ˜
Detractors (0-6):  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 28% ğŸ˜
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
NPS = 52% - 28% = +42 (Good)
```

**Customer Satisfaction (CSAT)**: 4.2/5 | **Target**: >4.0 | **Status**: âœ…

**Support Ticket Volume**: 87 tickets/week | **Trend**: â†˜ï¸ Decreasing

**First Response Time**: 2.3 hours | **Target**: <4 hours | **Status**: âœ…

**Resolution Time**: 18 hours | **Target**: <24 hours | **Status**: âœ…

---

### Financial KPIs

#### Budget Tracking

**Total Budget**: $600,000  
**Spent to Date**: $450,000 (75%)  
**Timeline Elapsed**: 80% of fiscal year  
**Status**: ğŸŸ¢ Under budget

```
ğŸ“Š Budget vs. Timeline:
Budget Spent:     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 75%
Timeline:         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 80%
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Burn Rate: 0.94 (Healthy - spending slower than time)
```

**Budget by Category**:
| Category | Budget | Spent | % | Status |
|----------|--------|-------|---|--------|
| Personnel | $400K | $320K | 80% | ğŸŸ¢ |
| Infrastructure | $120K | $85K | 71% | ğŸŸ¢ |
| Tooling & Licenses | $40K | $25K | 63% | ğŸŸ¢ |
| Contractors | $30K | $15K | 50% | ğŸŸ¢ |
| Training | $10K | $5K | 50% | ğŸŸ¢ |

---

#### Cost Efficiency

**Cost per Story Point**: $549 | **Target**: <$600 | **Status**: âœ…

**Cost per Feature**: $12,500 avg | **Trend**: â†˜ï¸ Decreasing (efficiency improving)

**Infrastructure Cost**: $2,800/month | **Budget**: $3,000/month | **Status**: ğŸŸ¢

**Cost per User**: $531 | **Trend**: â†˜ï¸ Decreasing as user base grows

---

### Team Health KPIs

#### Team Satisfaction

**Overall Satisfaction**: 7.8/10 | **Target**: >7.5 | **Status**: âœ…

**Satisfaction Breakdown**:
- Work-life balance: 8.2/10 âœ…
- Team collaboration: 8.5/10 âœ…
- Tools & resources: 7.5/10 âœ…
- Career growth: 7.0/10 ğŸŸ¡
- Recognition: 7.8/10 âœ…
- Process efficiency: 6.5/10 âš ï¸
- Leadership: 8.0/10 âœ…

---

#### Capacity & Utilization

**Team Size**: 27 members

**Capacity Utilization**: 82% | **Target**: 80-85% | **Status**: âœ…

**Planned Absences**: 3.5 days/person this sprint | **Impact**: Low

**Unplanned Absences**: 1.2 days/person | **Target**: <2 days | **Status**: âœ…

**Meeting Time**: 12.5 hours/week/person | **Target**: <10 hours | **Status**: ğŸŸ¡

---

#### Attrition & Retention

**Voluntary Attrition**: 5% annually | **Industry Average**: 13% | **Status**: âœ… Excellent

**New Hires (Last 6 months)**: 4 people

**Onboarding Time**: 4.5 weeks | **Target**: <6 weeks | **Status**: âœ…

**Time to Productivity**: 8 weeks | **Target**: <10 weeks | **Status**: âœ…

---

## Dashboard Widgets

### Real-Time Dashboards

#### Executive Dashboard
View live: [Executive Dashboard Link](#)

Widgets included:
- Program health status (RAG status)
- Sprint velocity trend
- Budget vs. actuals
- Top 5 risks
- User growth chart
- Quality metrics summary

---

#### Engineering Dashboard
View live: [Engineering Dashboard Link](#)

Widgets included:
- Sprint burndown chart
- Build success rate
- Test coverage trend
- Deployment frequency
- Bug trend
- Code quality metrics
- PR cycle time

---

#### Product Dashboard
View live: [Product Dashboard Link](#)

Widgets included:
- User growth & engagement
- Feature adoption rates
- NPS & CSAT scores
- Support ticket trends
- Roadmap progress
- Revenue metrics (if applicable)

---

## Metric Definitions

### Velocity
Total story points completed in a sprint. Calculated by summing story points of all work items in "Done" state at sprint end.

### Lead Time
Time from work item creation to deployment to production. Measures end-to-end delivery pipeline.

### Cycle Time
Time from work item "In Progress" to "Done". Measures active development time.

### Defect Density
Number of defects per 1,000 lines of code. Lower is better.

### Code Coverage
Percentage of code executed by automated tests. Higher is better, but diminishing returns >90%.

### MTTR (Mean Time To Recovery)
Average time to recover from a production incident. Lower is better.

### NPS (Net Promoter Score)
% Promoters - % Detractors. Range: -100 to +100. >0 is good, >50 is excellent.

### Burn Rate
Budget spent divided by timeline elapsed. <1.0 means under budget, >1.0 means over budget.

---

## Reporting Schedule

### Daily
- Build status (automated notifications)
- Sprint burndown (auto-updated)
- Active incident count

### Weekly
- Sprint progress report to leadership
- Velocity trend
- Quality metrics
- Top risks & blockers

### Bi-weekly (Sprint End)
- Sprint retrospective metrics
- Sprint summary report
- Demo day attendance & feedback

### Monthly
- Executive dashboard review
- Budget vs. actuals
- User growth & engagement
- Team satisfaction survey

### Quarterly
- Business review presentation
- OKR progress
- Strategic metrics
- Stakeholder satisfaction survey

---

## Alerts & Thresholds

### Automated Alerts

| Metric | Threshold | Alert Level | Recipients |
|--------|-----------|-------------|------------|
| Build failure | 2 consecutive failures | ğŸŸ¡ Warning | Team channel |
| Test coverage | Drops below 80% | ğŸ”´ Critical | Tech leads |
| API response time | P95 > 500ms | ğŸŸ¡ Warning | DevOps team |
| Production error rate | >1% of requests | ğŸ”´ Critical | On-call + PM |
| Deployment failure | Any failure | ğŸ”´ Critical | DevOps + leads |
| Sprint velocity | <70 SP | ğŸŸ¡ Warning | Delivery lead |
| Budget overrun | >5% over category budget | ğŸ”´ Critical | PM + Finance |
| NPS | <30 | ğŸŸ¡ Warning | Product Owner |
| Team satisfaction | <7.0 | ğŸ”´ Critical | PM + HR |

---

## Trend Analysis

### Positive Trends ğŸ“ˆ
1. **Quality improving**: Bug count decreased 80% over 6 sprints
2. **Velocity stabilizing**: Standard deviation reduced from Â±8 to Â±4 SP
3. **Deployment frequency up**: From 3/week to 8/week
4. **Code review faster**: 8 hours â†’ 4.2 hours average

### Areas of Concern ğŸ“‰
1. **User growth slowing**: Need to accelerate to hit Q1 target
2. **P2/P3 bug resolution time increasing**: Team prioritizing features over bugs
3. **Technical debt ratio climbing**: From 15% to 18% over 3 months
4. **Meeting time still high**: 12.5 hours/week vs 10-hour target

---

## Benchmarking

### Industry Comparisons

| Metric | Our Performance | Industry Average | Status |
|--------|-----------------|------------------|--------|
| Sprint Predictability | 94% | 75% | âœ… Excellent |
| Test Coverage | 85% | 70% | âœ… Above Average |
| Deployment Frequency | 8/week | 2-3/week | âœ… Excellent |
| Change Failure Rate | 8% | 15% | âœ… Excellent |
| MTTR | 1.8 hours | 4 hours | âœ… Excellent |
| Team Attrition | 5% | 13% | âœ… Excellent |
| NPS | 42 | 30 | âœ… Above Average |

**Overall**: Performing above industry standards in most categories. Focus areas: user growth, technical debt management.

---

## Quick Links

### Related Pages
- ğŸ“Š [Program Overview](/Program-Overview)
- ğŸ“… [Sprint Planning](/Sprint-Planning)
- ğŸ‘¥ [Capacity Planning](/Capacity-Planning)
- ğŸ—ºï¸ [Product Roadmap](/Roadmap)
- ğŸ¯ [RAID Log](/Risks-Issues)
- ğŸ”„ [Retrospective Insights](/Retrospectives)

### Live Dashboards
- [Executive Dashboard](link)
- [Engineering Dashboard](link)
- [Product Dashboard](link)
- [Quality Dashboard](link)

---

## ğŸ“š References

### Metrics & KPIs
- [DORA Metrics Guide](https://www.devops-research.com/research.html)
- [Azure DevOps Analytics](https://learn.microsoft.com/en-us/azure/devops/report/dashboards/)
- [Agile Metrics That Matter](https://www.atlassian.com/agile/project-management/metrics)

### Dashboard Best Practices
- [Data Visualization Best Practices](https://www.tableau.com/learn/articles/data-visualization-tips)
- [Building Effective Dashboards](https://hbr.org/2021/02/how-to-design-an-effective-dashboard)

### Benchmarking
- [State of DevOps Report](https://www.devops-research.com/research.html)
- [Accelerate (Book)](https://www.amazon.com/Accelerate-Software-Performing-Technology-Organizations/dp/1942788339)
